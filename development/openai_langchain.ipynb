{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohanbendapudi/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/rohanbendapudi/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.3 and will be removed in 0.3.0. Use PineconeVectorStore instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import vectorstores\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# hugging_face = HuggingFaceHubEmbeddings(huggingfacehub_api_token=os.getenv(\"HUGGING_FACE_API_KEY\"))\n",
    "pc = vectorstores.Pinecone(\n",
    "    pinecone_api_key=os.getenv(\"PINECONE_API_KEY\"),\n",
    "    embedding=openai_embeddings,\n",
    "    index_name=\"finalindex\",\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\", api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary keys of the PJT_INT_ATTRIBUTE_MAPPING table in Oracle Fusion Project Management are:\n",
      "\n",
      "1. ATTRIBUTE_MAPPING_ID: This is a unique identifier for each attribute mapping record in the table.\n",
      "2. PROJECT_ID: This key links the attribute mapping to a specific project within the system.\n",
      "\n",
      "These primary keys are essential for maintaining data integrity and ensuring accurate mapping of attributes within Oracle Fusion Project Management. If you need more specific details or guidance on working with the PJT_INT_ATTRIBUTE_MAPPING table, feel free to ask for further assistance.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain import hub\n",
    "\n",
    "# Load the system prompt\n",
    "with open(\"system_prompt.txt\", \"r\") as file:\n",
    "    system_prompt = file.read().replace(\"\\n\", \"\")\n",
    "\n",
    "# Get human input\n",
    "human = input(\"Enter your question: \")\n",
    "\n",
    "# Define the template\n",
    "template = f\"{system_prompt}\\n\\nQuestion: {human}\"\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "# Define the RAG chain\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": pc.as_retriever(k=2, search_type=\"similarity\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "result = rag_chain.invoke(human)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=' PJE_ISSUES_TL                \\t\\tTables and Views for Project ManagementPJE_ISSUES_TLPJE_ISSUES_TL   This is a MLS table for PJE_ISSUES_B Details   Schema: FUSION   Object owner: PJE   Object type: TABLE   Tablespace: FUSION_TS_TX_DATA    Primary Key   Name  Columns     PJE_ISSUES_TL_PK   ISSUE_ID, LANGUAGE, ENTERPRISE_ID     Columns   Name Datatype Length Precision Not-null Comments    ENTERPRISE_ID NUMBER  18 Yes Column to support multitenancy   ISSUE_ID NUMBER  18 Yes The Unique identifier of the Issue ,uses a global sequence ,refers PJE_ISSUES_B.ISSUE_ID   LANGUAGE VARCHAR2 4  Yes Indicates the code of the language into which the contents of the translatable columns are translated.   SOURCE_LANG VARCHAR2 4  Yes Indicates the code of the language in which the contents of the translatable columns were originally created.   CREATED_BY VARCHAR2 64  Yes Who column: indicates the user who created the row.   CREATION_DATE TIMESTAMP   Yes Who column: indicates the date and time of the creation of the row.   LAST_UPDATED_BY VARCHAR2 64  Yes Who column: indicates the user who last updated the row.   LAST_UPDATE_DATE TIMESTAMP   Yes Who column: indicates the date and time of the last update of the row.   LAST_UPDATE_LOGIN VARCHAR2 32   Who column: indicates the session login associated to the user who last updated the row.   OBJECT_VERSION_NUMBER NUMBER  9 Yes Used to implement optimistic locking. This number is incremented every time that the row is updated. The number is compared at the start and end of a transaction to detect whether another session has updated the row since it was queried.   SUMMARY VARCHAR2 150  Yes Summary   DESCRIPTION VARCHAR2 1000   Description   RESOLUTION VARCHAR2 1000   Resolution   REOPEN_SUMMARY VARCHAR2 1000   Used to store the reason for re-opening an issue.    Indexes   Index Uniqueness Tablespace Columns    PJE_ISSUES_TL_U1 Unique Default ISSUE_ID, LANGUAGE, ENTERPRISE_ID     ', metadata={'description': 'This is a MLS table for PJE_ISSUES_B', 'language': 'en', 'source': 'https://docs.oracle.com/en/cloud/saas/project-management/24a/oedpp/pjeissuestl-11433.html#pjeissuestl-11433', 'title': 'PJE_ISSUES_TL'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.similarity_search(query=\"What are the primary keys of PJE_ISSUES_TL?\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'input'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='{context}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Here, I can give you details on the table, and a SQL query to get the data'))]\n",
      "The columns of the `PJT_PLAN_VERSIONS` table are as follows:\n",
      "\n",
      "1. `PLAN_VERSION_ID`: System-generated identifier for the project plan version\n",
      "2. `PLAN_STATUS_CODE`: Indicates whether it is a \"baselined\", \"published\" or \"working\" version\n",
      "3. `PROJECT_ID`: Project for which the plan version is created\n",
      "4. `PUBLISHED_BY_PERSON_ID`: Resource Id of a person who published the project plan\n",
      "5. `PUBLISHED_DATE`: Date the most recent project plan version was published\n",
      "6. `OBJECT_VERSION_NUMBER`: Used to implement optimistic locking\n",
      "7. `CREATED_BY`: Who column: indicates the user who created the row\n",
      "8. `CREATION_DATE`: Who column: indicates the date and time of the creation of the row\n",
      "9. `LAST_UPDATED_BY`: Who column: indicates the user who last updated the row\n",
      "10. `LAST_UPDATE_DATE`: Who column: indicates the date and time of the last update of the row\n",
      "11. `LAST_UPDATE_LOGIN`: Who column: indicates the session login associated to the user who last updated the row\n",
      "12. `PARENT_STRUCTURE_VERSION_ID`: Version Id of the parent structure\n",
      "13. `ENTERPRISE_ID`: Enterprise ID\n",
      "14. `LAST_SCHEDULE_DATE`: Scheduling as of date chosen when project was last scheduled\n",
      "15. `FIN_DATES_REQUEST_ID`: This column indicates the Enterprise Service Schedule Request ID of the last submitted process\n",
      "16. `FIN_DATES_ESS_DATE`: Completion date of the Enterprise Service Schedule Request ID\n",
      "17. `FIN_DATES_ESS_STATUS`: Status of the project from the Enterprise Service Schedule Request ID\n",
      "18. `FIN_DATES_ESS_MSG_CODE`: Message Code from the Enterprise Service Schedule Request ID\n",
      "\n",
      "If you need a SQL query to retrieve the data from this table, please let me know.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "\n",
    "with open(\"system_prompt.txt\", \"r\") as file:\n",
    "    system_prompt = file.read().replace(\"\\n\", \"\")\n",
    "\n",
    "retriever = pc.as_retriever(k=3, search_type=\"similarity\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"{context}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\n",
    "            \"ai\",\n",
    "            \"Here, I can give you details on the table, and a SQL query to get the data\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"context\": system_prompt, \"input\": input()})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run e52f37f7-179f-47a1-ad23-7df25cb0d4a3 not found for run 3b08b4f1-8836-4a68-9c1d-7d0386148b34. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary key of PJT_PLAN_VERSIONS is PLAN_VERSION_ID.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run c4fe0fa7-7f09-4233-b87a-7b9171570a70 not found for run 019838b5-3faf-4086-8d95-a21fd340d88d. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of PJT_PLAN_VERSIONS are:\n",
      "1. PLAN_VERSION_ID\n",
      "2. PLAN_STATUS_CODE\n",
      "3. PROJECT_ID\n",
      "4. PUBLISHED_BY_PERSON_ID\n",
      "5. PUBLISHED_DATE\n",
      "6. OBJECT_VERSION_NUMBER\n",
      "7. CREATED_BY\n",
      "8. CREATION_DATE\n",
      "9. LAST_UPDATED_BY\n",
      "10. LAST_UPDATE_DATE\n",
      "11. LAST_UPDATE_LOGIN\n",
      "12. PARENT_STRUCTURE_VERSION_ID\n",
      "13. ENTERPRISE_ID\n",
      "14. LAST_SCHEDULE_DATE\n",
      "15. FIN_DATES_REQUEST_ID\n",
      "16. FIN_DATES_ESS_DATE\n",
      "17. FIN_DATES_ESS_STATUS\n",
      "18. FIN_DATES_ESS_MSG_CODE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 12eb0482-bc2d-4cd3-ab6e-72f96c685a41 not found for run 0909c8b4-9956-4126-9e5f-25657cc056ad. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I see that you haven't provided a question or follow-up. If you have any more questions or need further assistance, feel free to ask!\n",
      "\n",
      "Goodbye!!!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "retriever = pc.as_retriever()\n",
    "\n",
    "\n",
    "### Contextualize question ###\n",
    "contextualize_q_system_prompt = system_prompt\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "\n",
    "### Answer question ###\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriever, question_answer_chain)\n",
    "\n",
    "\n",
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    query = input(\"Ask a question, type 'exit' to finish: \\n\")\n",
    "\n",
    "    if query == \"exit\":\n",
    "        print(\"Goodbye!!!\")\n",
    "        break\n",
    "    else:\n",
    "        answer = conversational_rag_chain.invoke(\n",
    "            {\"input\": query, \"context\": system_prompt}, config={\"configurable\": {\"session_id\": \"abc123\"}}\n",
    "        )[\"answer\"]\n",
    "        print(answer + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
